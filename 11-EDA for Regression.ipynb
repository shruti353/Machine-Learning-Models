{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA for Regression Task\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load your dataset\n",
    "# For demonstration, let's use a sample dataset (replace this with your actual dataset)\n",
    "dataset = sns.load_dataset('tips')  # Using the 'tips' dataset for demonstration\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Head:\")\n",
    "print(dataset.head())\n",
    "\n",
    "# Display dataset info to check for missing values, data types, etc.\n",
    "print(\"\\nDataset Info:\")\n",
    "print(dataset.info())\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "print(\"\\nMissing Values:\")\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "# Handle missing values if necessary (imputation)\n",
    "# Here, we use SimpleImputer to fill missing values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "dataset_imputed = pd.DataFrame(imputer.fit_transform(dataset.select_dtypes(include=[np.number])), columns=dataset.select_dtypes(include=[np.number]).columns)\n",
    "\n",
    "# Merge imputed numerical columns back with categorical data\n",
    "dataset[dataset_imputed.columns] = dataset_imputed\n",
    "\n",
    "# Check if missing values are handled\n",
    "print(\"\\nMissing Values After Imputation:\")\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(\"\\nDuplicate Rows:\")\n",
    "print(dataset.duplicated().sum())\n",
    "\n",
    "# Drop duplicate rows if any\n",
    "dataset = dataset.drop_duplicates()\n",
    "\n",
    "# EDA Visualizations\n",
    "# 1. Distribution of Target Variable ('total_bill' is the target variable)\n",
    "sns.histplot(dataset['total_bill'], kde=True)\n",
    "plt.title('Distribution of Total Bill')\n",
    "plt.xlabel('Total Bill')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 2. Pairplot to understand relationships between features\n",
    "sns.pairplot(dataset[['total_bill', 'tip', 'size']])\n",
    "plt.show()\n",
    "\n",
    "# 3. Correlation heatmap to analyze relationships between numerical features\n",
    "corr_matrix = dataset.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# 4. Boxplot to check for outliers in numerical features\n",
    "sns.boxplot(x=dataset['total_bill'])\n",
    "plt.title('Boxplot for Total Bill')\n",
    "plt.show()\n",
    "\n",
    "# 5. Scatter plot to visualize relationships between numerical features (e.g., 'total_bill' vs 'tip')\n",
    "sns.scatterplot(x=dataset['total_bill'], y=dataset['tip'])\n",
    "plt.title('Scatter Plot: Total Bill vs Tip')\n",
    "plt.xlabel('Total Bill')\n",
    "plt.ylabel('Tip')\n",
    "plt.show()\n",
    "\n",
    "# 6. Histogram of numerical features (e.g., 'tip')\n",
    "sns.histplot(dataset['tip'], kde=True)\n",
    "plt.title('Distribution of Tip')\n",
    "plt.xlabel('Tip')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 7. Pairplot to explore relationships between multiple features\n",
    "sns.pairplot(dataset[['total_bill', 'tip', 'size', 'day']])\n",
    "plt.show()\n",
    "\n",
    "# Categorical Feature: 'day' (One-Hot Encoding)\n",
    "# Convert categorical features into numerical features using OneHotEncoding\n",
    "encoder = pd.get_dummies(dataset['day'], drop_first=True)\n",
    "\n",
    "# Add encoded columns back to the dataset\n",
    "dataset = pd.concat([dataset, encoder], axis=1)\n",
    "\n",
    "# Drop the original categorical column 'day' after encoding\n",
    "dataset = dataset.drop(columns=['day'])\n",
    "\n",
    "# Display the updated dataset after One-Hot Encoding\n",
    "print(\"\\nDataset after One-Hot Encoding:\")\n",
    "print(dataset.head())\n",
    "\n",
    "# Train-Test Split\n",
    "# Let's assume 'total_bill' is the target variable for regression\n",
    "X = dataset.drop(columns=['total_bill', 'tip'])  # Drop target columns\n",
    "y = dataset['total_bill']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standard Scaling for regression models\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Final dataset ready for modeling\n",
    "print(\"\\nTraining Set Shape:\", X_train_scaled.shape)\n",
    "print(\"Test Set Shape:\", X_test_scaled.shape)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
