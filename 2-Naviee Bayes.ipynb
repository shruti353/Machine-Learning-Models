{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d02b8d",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes\n",
    "Use case: Continuous data (e.g., financial ratios, age, height)\n",
    "\n",
    "Scaling: Recommended (StandardScaler or MinMaxScaler)\n",
    "\n",
    "Loss Function: Not defined explicitly; use Accuracy, Log Loss, or Negative Log Likelihood\n",
    "\n",
    "Key Parameters:\n",
    "\n",
    "var_smoothing: Portion of the largest variance added to all variances for stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4356adc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example dataset (replace with your own)\n",
    "X, y = datasets.make_classification(n_samples=500, n_features=10, random_state=42)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "gnb = GaussianNB(var_smoothing=1e-9)\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "y_proba = gnb.predict_proba(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Log Loss: {log_loss(y_test, y_proba):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b9738",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes\n",
    "Use case: Count/frequency data (e.g., word counts, bag-of-words, number of clicks)\n",
    "\n",
    "Scaling: Do not scale with StandardScaler; use raw counts or normalize if needed.\n",
    "\n",
    "Loss Function: Accuracy, Log Loss\n",
    "\n",
    "Key Parameters:\n",
    "\n",
    "alpha: Laplace smoothing parameter\n",
    "\n",
    "fit_prior: Learn class prior from training data\n",
    "\n",
    "class_prior: Manually set prior probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246611d3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "\n",
    "# Use pre-vectorized text data\n",
    "data = fetch_20newsgroups_vectorized()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "mnb = MultinomialNB(alpha=1.0)\n",
    "mnb.fit(X_train, y_train)\n",
    "y_pred = mnb.predict(X_test)\n",
    "y_proba = mnb.predict_proba(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Log Loss: {log_loss(y_test, y_proba):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d2a346",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes\n",
    "Use case: Binary features (e.g., yes/no, 0/1 presence)\n",
    "\n",
    "Scaling: Not needed â€” input should be binary (0/1)\n",
    "\n",
    "Loss Function: Accuracy, Log Loss\n",
    "\n",
    "Key Parameters:\n",
    "\n",
    "alpha: Laplace smoothing\n",
    "\n",
    "binarize: Threshold for converting values to 0/1\n",
    "\n",
    "fit_prior: Whether to learn class prior\n",
    "\n",
    "class_prior: Manually specify class prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d331ad89",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Generate data\n",
    "X, y = datasets.make_classification(n_samples=500, n_features=10, random_state=42)\n",
    "\n",
    "# Binarize features\n",
    "binarizer = Binarizer(threshold=0.0)\n",
    "X_binary = binarizer.fit_transform(X)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_binary, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "bnb = BernoulliNB(alpha=1.0, binarize=None)\n",
    "bnb.fit(X_train, y_train)\n",
    "y_pred = bnb.predict(X_test)\n",
    "y_proba = bnb.predict_proba(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Log Loss: {log_loss(y_test, y_proba):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
