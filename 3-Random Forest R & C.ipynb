{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0203d4ec",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "Use Case: Classification problems (e.g., spam detection, stock movement: up/down)\n",
    "\n",
    "Scaling:  Not required (tree-based models are scale-invariant)\n",
    "\n",
    "Loss/Score Functions: Accuracy, F1-score, ROC-AUC, Log Loss (probabilistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feecded8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate sample data\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, random_state=42)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=100,        # number of trees\n",
    "    max_depth=None,          # depth of each tree\n",
    "    min_samples_split=2,     # min samples to split an internal node\n",
    "    min_samples_leaf=1,      # min samples at a leaf\n",
    "    max_features='sqrt',     # number of features to consider at each split\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_proba[:,1]):.4f}\")\n",
    "print(f\"Log Loss: {log_loss(y_test, y_proba):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce991711",
   "metadata": {},
   "source": [
    "## Random Forest Regressor\n",
    "Use Case: Regression problems (e.g., stock price prediction, house prices)\n",
    "\n",
    "Scaling:  Not required\n",
    "\n",
    "Loss/Score Functions: MSE, RMSE, MAE, R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10900a88",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Generate sample regression data\n",
    "X, y = make_regression(n_samples=1000, n_features=10, noise=0.3, random_state=42)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "reg = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45c5ab",
   "metadata": {},
   "source": [
    "## \n",
    "Parameter\tMeaning\n",
    "\n",
    "n_estimators\tNumber of trees in the forest\n",
    "\n",
    "max_depth\tMaximum depth of each tree\n",
    "\n",
    "min_samples_split\tMinimum samples required to split an internal node\n",
    "\n",
    "min_samples_leaf\tMinimum samples at a leaf node\n",
    "\n",
    "max_features\tNumber of features to consider when looking for best split\n",
    "\n",
    "random_state\tEnsures reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2152d3ae",
   "metadata": {},
   "source": [
    "## Random Forest Classifier – GridSearchCV\n",
    "\n",
    "Parameters we're tuning:\n",
    "n_estimators: Number of trees\n",
    "\n",
    "max_depth: Max depth of tree\n",
    "\n",
    "min_samples_split: Minimum number of samples to split a node\n",
    "\n",
    "min_samples_leaf: Minimum number of samples at a leaf node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e33b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_clf = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", grid_clf.best_params_)\n",
    "\n",
    "# Final evaluation\n",
    "y_pred = grid_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80845f44",
   "metadata": {},
   "source": [
    "## Random Forest Regressor – GridSearchCV\n",
    "\n",
    "Parameters we're tuning:\n",
    "\n",
    "Same as above, but used for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627dcf9f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, noise=0.3, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_reg = GridSearchCV(reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_reg.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", grid_reg.best_params_)\n",
    "\n",
    "# Final evaluation\n",
    "y_pred = grid_reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caee153",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV for Random Forest Regressor\n",
    "\n",
    "#### 1. **`param_grid = { ... }`**\n",
    "\n",
    "This dictionary defines the **hyperparameters** and the **values you want to test** for each one during the tuning process. GridSearchCV will try all combinations of these values and return the best one.\n",
    "\n",
    "- **`n_estimators`**: Number of trees in the random forest. Here we are testing values [50, 100].\n",
    "- **`max_depth`**: Maximum depth of each tree. We are testing values `None` (no limit) and 10, 20 as potential limits.\n",
    "- **`min_samples_split`**: Minimum number of samples required to split an internal node. We are testing values 2 and 5.\n",
    "- **`min_samples_leaf`**: Minimum number of samples required to be at a leaf node. We are testing values 1 and 2.\n",
    "\n",
    "This results in **3 × 2 × 2 × 2 = 24** different combinations of hyperparameters.\n",
    "\n",
    "#### 2. **Creating the GridSearchCV Object**\n",
    "\n",
    "```python\n",
    "grid_reg = GridSearchCV(reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "reg: The base model you want to tune, which is a RandomForestRegressor.\n",
    "\n",
    "param_grid: The dictionary from above, specifying the parameters to be tested.\n",
    "\n",
    "cv=5: We are using 5-fold cross-validation, meaning the dataset will be split into 5 parts and the model will be trained and evaluated 5 times (with each part acting as the test set once).\n",
    "\n",
    "scoring='neg_mean_squared_error': The negative mean squared error (MSE) is used as the scoring function. The reason it’s negative is that scikit-learn aims to maximize the score, so by using negative MSE, it will effectively minimize MSE.\n",
    "\n",
    "n_jobs=-1: Using all CPU cores available to speed up the search process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2ead56",
   "metadata": {},
   "source": [
    "3. Fitting the GridSearchCV\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "grid_reg.fit(X_train, y_train)\n",
    "This runs the grid search to find the best combination of parameters.\n",
    "\n",
    "It tries all 24 combinations of the hyperparameters in param_grid.\n",
    "\n",
    "The model is trained and evaluated using 5-fold cross-validation for each combination.\n",
    "\n",
    "After this, the grid search will pick the best-performing combination based on the lowest negative MSE score.\n",
    "\n",
    "4. Accessing the Results\n",
    "You can retrieve the best-performing model and its parameters:\n",
    "\n",
    "Best parameters:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "grid_reg.best_params_      # Best hyperparameter combination found\n",
    "Best score (Negative MSE):\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "grid_reg.best_score_       # Best negative mean squared error across all folds\n",
    "Best estimator (trained model with best params):\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "grid_reg.best_estimator_   # The fully trained model with the best combination of parameters\n",
    "5. Summary\n",
    "param_grid specifies the range of values for the hyperparameters to test.\n",
    "\n",
    "GridSearchCV is used to perform a comprehensive search for the best parameter combination.\n",
    "\n",
    "The grid search uses 5-fold cross-validation and evaluates the models based on negative mean squared error.\n",
    "\n",
    "After fitting, the best-performing model and its hyperparameters can be retrieved using best_params_, best_score_, and best_estimator_.\n",
    "\n",
    "yaml\n",
    "Copy\n",
    "Edit\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
